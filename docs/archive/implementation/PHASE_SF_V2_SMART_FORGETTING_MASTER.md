# Phase SF-V2: Smart Forgetting Implementation
**Date:** 2025-11-24
**Philosophy:** à¤µà¤¿à¤¸à¥à¤®à¥ƒà¤¤à¤¿ à¤­à¥€ à¤µà¤¿à¤¦à¥à¤¯à¤¾ à¤¹à¥ˆ (Forgetting too is knowledge)

---

## ðŸŽ¯ Vision

Transform Vidurai's memory system from **literal storage** â†’ **experiential semantic retention**.

### Core Principle
Preserve **WHY-HOW-RESULT** and **technical entities** while still providing compression & forgetting.

**Current Problem:**
- Compression can lose critical technical details
- No distinction between "cause" and "noise"
- No way to pin important memories
- COST_FOCUSED mode too aggressive
- Forgetting events lack transparency

**SF-V2 Solution:**
- Intelligent role classification (cause/fix/resolution/context/noise)
- Retention scoring with multiple factors
- Entity extraction (preserve error messages, file paths, function names)
- Smart compression format (cause â†’ fix â†’ result â†’ learning)
- Memory pinning for critical knowledge
- Transparent auditability of all forgetting

---

## ðŸ“‹ Architecture Overview

### Current System (Baseline)

```
Memory Ingestion
 â†“
Salience Classification (CRITICAL/HIGH/MEDIUM/LOW/NOISE)
 â†“
Aggregation (duplicate detection)
 â†“
Retention Policy (Rule-based or RL-based)
 â†“
Semantic Consolidation (batch compression)
 â†“
Storage
```

**Existing Components:**
1. **Memory Aggregator** (`vidurai/core/memory_aggregator.py`)
 - Fingerprinting for duplicate detection
 - Occurrence counting
 - Salience adjustment (2-5 occurrences â†’ downgrade)

2. **Retention Policy** (`vidurai/core/retention_policy.py`)
 - Abstract interface
 - RuleBasedPolicy (thresholds: 100/500/1000)
 - RLPolicy (uses VismritiRLAgent)

3. **Semantic Consolidation** (`vidurai/core/semantic_consolidation.py`)
 - Batch job for grouping and consolidating
 - File-based grouping
 - Simple text-based compression

### SF-V2 Enhanced System

```
Memory Ingestion
 â†“
[NEW] Memory Role Classification (cause/attempted_fix/resolution/context/noise)
 â†“
[NEW] Entity Extraction (preserve technical identifiers)
 â†“
[ENHANCED] Salience Classification + Retention Scoring
 â†“
[ENHANCED] Aggregation (with entity preservation)
 â†“
[ENHANCED] Retention Policy (uses retention score)
 â†“
[NEW] Intelligence-Preserving Compression (cause/fix/result/learning)
 â†“
[NEW] Pin Check (pinned memories never compressed)
 â†“
Storage + [NEW] Transparency Log
```

---

## ðŸ”§ Implementation Phases

### Phase SF-2.1: Memory Role Classification
**File:** `vidurai/core/memory_role_classifier.py` (NEW)

**Purpose:** Classify each memory by its role in the development narrative.

**Memory Roles:**
- `cause` - Root cause identification (e.g., "JWT timestamp mismatch")
- `attempted_fix` - Debugging attempts that failed
- `resolution` - Successful solution
- `context` - Background information
- `noise` - Redundant or low-value content

**Classification Logic:**
```python
class MemoryRole(Enum):
 CAUSE = "cause"
 ATTEMPTED_FIX = "attempted_fix"
 RESOLUTION = "resolution"
 CONTEXT = "context"
 NOISE = "noise"

class MemoryRoleClassifier:
 def classify(self, memory: Memory) -> MemoryRole:
 """
 Classify memory role using keyword matching and heuristics

 Priority:
 1. Resolution keywords: "fixed", "solved", "working now"
 2. Cause keywords: "root cause", "issue is", "problem:"
 3. Attempted fix: "tried", "attempted", "debugging"
 4. Context: general observations
 5. Noise: duplicates, trivial info
 """
```

**Integration Points:**
- Called in `VismritiMemory.remember()` after salience classification
- Stored in memory metadata (new field: `role`)
- Used by retention scoring engine

**Test Coverage:**
- Test resolution detection
- Test cause identification
- Test attempted_fix vs resolution
- Test noise classification

**Success Criteria:**
- 90%+ accuracy on labeled test set
- Resolution memories scored higher than noise
- No breaking changes to existing APIs

---

### Phase SF-2.2: Entity Extraction Layer
**File:** `vidurai/core/entity_extractor.py` (NEW)

**Purpose:** Extract and preserve technical entities that must NEVER be lost during compression.

**Entity Types:**
- Error messages: `"TypeError: Cannot read property 'x' of undefined"`
- Stack traces: file paths + line numbers
- Function/method names: `authenticateUser()`, `validateToken()`
- Variable names: `jwt_timestamp`, `auth_token`
- Config keys: `API_KEY`, `DATABASE_URL`
- Database fields: `user.email`, `session.expires_at`
- Timestamps: ISO 8601 dates
- Environment references: `NODE_ENV=production`

**Implementation:**
```python
@dataclass
class ExtractedEntities:
 error_messages: List[str]
 stack_traces: List[Dict[str, Any]] # {file, line, function}
 identifiers: List[str] # function/variable/config names
 file_paths: List[str]
 timestamps: List[str]
 environment: Dict[str, str]

 def to_dict(self) -> Dict[str, Any]:
 """Serialize for storage"""
 pass

class EntityExtractor:
 def extract(self, text: str) -> ExtractedEntities:
 """
 Extract technical entities using regex patterns

 Patterns:
 - Error: r'(Error|Exception|Failed).*?:'
 - Stack trace: r'at (.+?):(\d+):(\d+)'
 - Function: r'\b\w+\(.*?\)'
 - File path: r'[\w/.-]+\.(js|py|ts|tsx|jsx|go|rs|java)'
 - ISO timestamp: r'\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}'
 """
```

**Integration Points:**
- Called before compression in `SemanticConsolidationJob`
- Entities stored alongside compressed memory
- Entities included in queries/recalls

**Test Coverage:**
- Test error message extraction
- Test stack trace parsing
- Test function name detection
- Test file path extraction
- Test preservation during compression

**Success Criteria:**
- 100% of error messages preserved
- Stack traces intact after compression
- Function names never lost
- Compressed memories still useful for debugging

---

### Phase SF-2.3: Retention Scoring Engine
**File:** `vidurai/core/retention_score.py` (NEW)

**Purpose:** Calculate multi-factor retention score to guide forgetting decisions.

**Formula:**
```
retention_score =
 salience_weight (0-40 points) +
 usage_count_weight (0-20 points) +
 recency_weight (0-15 points) +
 rl_reward_weight (0-10 points) +
 technical_density_weight (0-10 points) +
 root_cause_value (0-15 points) +
 role_priority (0-20 points) +
 pin_bonus (0 or +100)

Total range: 0-100 (or 100-200 if pinned)
```

**Component Weights:**

1. **Salience Weight** (0-40):
 - CRITICAL: 40
 - HIGH: 30
 - MEDIUM: 20
 - LOW: 10
 - NOISE: 0

2. **Usage Count Weight** (0-20):
 - `min(access_count * 2, 20)`
 - Frequently accessed â†’ higher retention

3. **Recency Weight** (0-15):
 - Accessed within 24h: 15
 - Accessed within 7d: 10
 - Accessed within 30d: 5
 - Older: 0

4. **RL Reward Weight** (0-10):
 - If RL policy enabled, use RL agent's Q-value
 - Normalized to 0-10 range

5. **Technical Density Weight** (0-10):
 - Presence of entities: `min(entity_count, 10)`
 - More technical details â†’ higher retention

6. **Root Cause Value** (0-15):
 - Memory contains root cause analysis: +15
 - Helps understand "why"

7. **Role Priority** (0-20):
 - resolution: 20
 - cause: 18
 - attempted_fix: 12
 - context: 8
 - noise: 0

8. **Pin Bonus** (+100 if pinned):
 - Pinned memories score 100-200
 - Effectively immune to forgetting

**Implementation:**
```python
@dataclass
class RetentionScore:
 total: float # 0-200
 salience_component: float
 usage_component: float
 recency_component: float
 rl_component: float
 technical_density_component: float
 root_cause_component: float
 role_component: float
 pinned: bool

 def should_forget(self, threshold: float = 30) -> bool:
 """True if score below threshold"""
 return self.total < threshold

class RetentionScoreEngine:
 def calculate_score(
 self,
 memory: Memory,
 role: MemoryRole,
 entities: ExtractedEntities,
 rl_value: Optional[float] = None
 ) -> RetentionScore:
 """Calculate comprehensive retention score"""
```

**Integration Points:**
- Called by `RetentionPolicy` to decide actions
- Replaces simple salience-based decisions
- Used by consolidation job for prioritization

**Test Coverage:**
- Test pinned memories always score high
- Test resolution > cause > attempted_fix > noise
- Test technical density increases score
- Test recency bonus
- Test edge cases (all zeros, all maxes)

**Success Criteria:**
- Pinned memories never forgotten
- Resolution memories outlive noise
- Technical details preserved longer
- Scores correlate with actual usefulness

---

### Phase SF-2.4: Intelligence-Preserving Compression
**File:** Enhance `vidurai/core/semantic_consolidation.py`

**Purpose:** Compress memories while preserving semantic meaning and technical details.

**Before SF-V2:**
```
"Error in auth.py line 42: JWT validation failed (Ã—50 over 3 days)"
```

**After SF-V2:**
```
Cause: JWT timestamp mismatch (UNIX vs ISO format)
Fix: Normalized datetime.utcnow().timestamp() conversion
Result: Authentication stable, 0 errors in 7 days
Learning: Always use consistent timezone handling
Entities: [auth.py:42, validateToken(), jwt_timestamp, TypeError]
```

**Compression Format:**
```python
@dataclass
class CompressedMemory:
 cause: str # What was the problem?
 fix: str # What did we do?
 result: str # What happened?
 learning: str # What did we learn?
 entities: ExtractedEntities # Technical details
 metadata: Dict[str, Any] # Original timestamps, files, etc.

 def to_gist(self) -> str:
 """Generate concise gist for display"""
 return f"{self.cause} â†’ {self.fix} â†’ {self.result}"
```

**Compression Strategy:**

1. **Group Phase** (existing):
 - Group by file path
 - Group by time window (7 days)
 - Group by error type

2. **Analysis Phase** (NEW):
 - Extract entities from all memories in group
 - Identify cause memories (role=cause)
 - Identify resolution memories (role=resolution)
 - Identify attempted fixes (role=attempted_fix)

3. **Synthesis Phase** (NEW):
 - **Cause**: First cause memory or inferred from errors
 - **Fix**: Last resolution memory or most common attempted fix
 - **Result**: Outcome (fixed/ongoing/unknown)
 - **Learning**: Pattern extracted from resolutions
 - **Entities**: Union of all entities in group

4. **Preservation Phase** (NEW):
 - Store entities separately
 - Store original timestamps
 - Store rollup metadata (occurrence count, time span)
 - Mark as "compressed" in tags

**Integration Points:**
- Enhance `_consolidate_group()` in `SemanticConsolidationJob`
- Store `CompressedMemory` format in database
- Update queries to handle compressed format
- CLI displays compressed format with entities

**Test Coverage:**
- Test cause extraction
- Test fix identification
- Test learning synthesis
- Test entity preservation
- Test compressed memory queries
- Test decompression for display

**Success Criteria:**
- Compressed memories preserve root cause
- AI can solve problem from compressed memory
- No loss of technical identifiers
- Human-readable format

---

### Phase SF-2.5: Memory Pinning System
**Files:**
- `vidurai/core/memory_pinning.py` (NEW)
- `vidurai/cli.py` (ENHANCE)
- `vidurai/storage/database.py` (ENHANCE)

**Purpose:** Allow users to pin critical memories that should NEVER be compressed, consolidated, or forgotten.

**CLI Commands:**
```bash
# Pin a memory
vidurai pin <memory_id>
vidurai pin --query "JWT authentication fix"

# Unpin a memory
vidurai unpin <memory_id>

# List pinned memories
vidurai pins
vidurai pins --project /path/to/project

# Show pin status
vidurai recall --query "auth" --show-pins
```

**Database Changes:**
```sql
-- Add pinned column to memories table
ALTER TABLE memories ADD COLUMN pinned INTEGER DEFAULT 0;

-- Index for fast pin queries
CREATE INDEX idx_memories_pinned ON memories(pinned) WHERE pinned = 1;
```

**Pinning Rules:**
1. Pinned memories:
 - Cannot be merged/consolidated
 - Cannot be dropped/deleted (except manual unpin)
 - Cannot be compressed
 - Cannot decay with age
 - Always included in relevant queries

2. Pin limits:
 - Default: 50 pins per project
 - Configurable via `~/.vidurai/config.json`
 - Warning when approaching limit

3. Auto-pin candidates:
 - User-created memories (from CLI remember)
 - Memories with salience=CRITICAL
 - Resolution memories with high retention score

**Implementation:**
```python
class MemoryPinManager:
 def __init__(self, db):
 self.db = db
 self.max_pins_per_project = 50

 def pin(self, memory_id: int, reason: Optional[str] = None) -> bool:
 """Pin a memory"""
 # Check limit
 # Update database
 # Log pin event
 pass

 def unpin(self, memory_id: int) -> bool:
 """Unpin a memory"""
 pass

 def is_pinned(self, memory_id: int) -> bool:
 """Check if memory is pinned"""
 pass

 def get_pinned_memories(self, project_path: str) -> List[Memory]:
 """Get all pinned memories for project"""
 pass

 def suggest_pins(self, project_path: str) -> List[Memory]:
 """Suggest memories worth pinning"""
 # High retention score
 # Frequently accessed
 # Resolution role
 pass
```

**Integration Points:**
- `RetentionPolicy`: Skip pinned memories
- `SemanticConsolidationJob`: Exclude pinned from consolidation
- `VismritiMemory.forget()`: Cannot forget pinned
- `CLI recall`: Show pin indicator (ðŸ“Œ)

**Test Coverage:**
- Test pin/unpin operations
- Test pinned memory exclusion from consolidation
- Test pin limit enforcement
- Test pin suggestions
- Test pin persistence across restarts

**Success Criteria:**
- Pinned memories never lost
- CLI commands work correctly
- Pin limit enforced
- Performance unaffected (<10ms overhead)

---

### Phase SF-2.6: Default Profile Change & Warnings
**Files:**
- `vidurai/core/rl_agent_v2.py` (ENHANCE)
- `vidurai/cli.py` (ENHANCE)

**Purpose:** Change default reward profile to BALANCED and add warnings for COST_FOCUSED mode.

**Changes:**

1. **Default Profile Change:**
 ```python
 # OLD (in rl_agent_v2.py)
 DEFAULT_PROFILE = RewardProfile.QUALITY_FOCUSED

 # NEW
 DEFAULT_PROFILE = RewardProfile.BALANCED
 ```

2. **COST_FOCUSED Warning:**
 ```python
 # In VismritiMemory.__init__() or RL policy init
 if reward_profile == "COST_FOCUSED":
 logger.warning(
 "âš ï¸ COST_FOCUSED mode may remove detail and nuance.\n"
 " Critical technical identifiers will be preserved.\n"
 " Consider BALANCED mode for better quality retention."
 )
 ```

3. **CLI Warning:**
 ```bash
 $ vidurai config --profile COST_FOCUSED

 âš ï¸ Warning: COST_FOCUSED Mode

 This profile prioritizes:
 â€¢ Aggressive compression (may lose context)
 â€¢ Minimal token usage (gists over verbatim)
 â€¢ Fast forgetting (shorter retention windows)

 Preserved:
 âœ“ Error messages, stack traces
 âœ“ Function names, file paths
 âœ“ Root causes and resolutions
 âœ“ Pinned memories

 Lost:
 âœ— Detailed context
 âœ— Debugging history
 âœ— Nuanced observations

 Continue? [y/N]
 ```

4. **Profile Comparison Table:**
 ```
 Feature | QUALITY | BALANCED | COST
 ---------------------|------------|------------|------------
 Compression | Light | Moderate | Aggressive
 Retention (days) | 90-365 | 30-180 | 7-90
 Entity Preservation | 100% | 100% | 100%
 Context Detail | High | Medium | Low
 Token Usage | High | Medium | Low
 Recommended For | Research | General | High-volume
 ```

**Integration Points:**
- Update documentation (README, CLI help)
- Update config file templates
- Add profile info to `vidurai status` output

**Test Coverage:**
- Test default is BALANCED
- Test COST_FOCUSED warning displayed
- Test entity preservation in all profiles
- Test profile comparison accuracy

**Success Criteria:**
- New users get BALANCED by default
- COST_FOCUSED users see warning
- Entities preserved in all profiles
- Clear documentation of tradeoffs

---

### Phase SF-2.7: Transparency & Auditability
**Files:**
- `vidurai/core/forgetting_ledger.py` (NEW)
- `vidurai/cli.py` (ENHANCE)

**Purpose:** Log every forgetting event with full transparency for debugging and trust.

**Ledger Format:**
```json
{
 "timestamp": "2025-11-24T10:30:00Z",
 "event": "consolidation",
 "action": "compress_aggressive",
 "project": "/home/user/project",
 "details": {
 "memories_before": 150,
 "memories_after": 45,
 "compression_ratio": 0.70,
 "memories_removed": [123, 456, 789],
 "consolidated_into": [900, 901],
 "entities_preserved": 42,
 "root_causes_preserved": 5,
 "resolutions_preserved": 8
 },
 "reason": "Memory count exceeded 100 LOW/NOISE threshold",
 "policy": "rule_based",
 "reversible": false
}
```

**Ledger Implementation:**
```python
@dataclass
class ForgettingEvent:
 timestamp: datetime
 event_type: str # consolidation, decay, deletion, aggregation
 action: str # RetentionAction.value
 project_path: str
 memories_before: int
 memories_after: int
 memories_removed: List[int]
 consolidated_into: List[int]
 entities_preserved: int
 root_causes_preserved: int
 resolutions_preserved: int
 reason: str
 policy: str
 reversible: bool

class ForgettingLedger:
 def __init__(self, ledger_path: str = "~/.vidurai/forgetting_ledger.jsonl"):
 self.ledger_path = Path(ledger_path).expanduser()
 self.ledger_path.parent.mkdir(parents=True, exist_ok=True)

 def log_event(self, event: ForgettingEvent):
 """Append event to ledger"""
 with open(self.ledger_path, 'a') as f:
 f.write(json.dumps(asdict(event), default=str) + '\n')

 def get_events(
 self,
 project: Optional[str] = None,
 limit: int = 100
 ) -> List[ForgettingEvent]:
 """Query recent events"""
 pass

 def get_statistics(self) -> Dict[str, Any]:
 """Aggregate statistics"""
 # Total events
 # By event type
 # Total memories removed
 # Entities preserved count
 pass
```

**CLI Commands:**
```bash
# View forgetting history
vidurai forgetting-log
vidurai forgetting-log --limit 50
vidurai forgetting-log --project /path/to/project

# Show summary statistics
vidurai forgetting-stats

# Example output:
ðŸ“‹ Forgetting Log (last 10 events)

[2025-11-24 10:30:00] CONSOLIDATION
 Action: compress_aggressive
 Reason: Memory count exceeded 100 LOW/NOISE threshold
 Impact: 150 â†’ 45 memories (70% reduction)
 Preserved: 42 entities, 5 root causes, 8 resolutions
 Policy: rule_based
 Reversible: No

[2025-11-24 09:15:00] AGGREGATION
 Action: auto_merge
 Reason: Duplicate error detected (Ã—12 occurrences)
 Impact: 12 â†’ 1 memories
 Preserved: 3 entities, 1 root cause
 Policy: aggregation
 Reversible: Yes (within 24h)
```

**Integration Points:**
- `SemanticConsolidationJob`: Log after consolidation
- `MemoryAggregator`: Log after aggregation
- `RetentionPolicy`: Log after decay
- `VismritiMemory.forget()`: Log manual deletions

**Test Coverage:**
- Test event logging
- Test query filtering
- Test statistics calculation
- Test ledger persistence
- Test large ledger performance

**Success Criteria:**
- Every forgetting event logged
- Ledger queryable via CLI
- Statistics accurate
- User trust increased

---

### Phase SF-2.8: Comprehensive Testing Suite
**Files:**
- `test_memory_role_classifier.py` (NEW)
- `test_entity_extractor.py` (NEW)
- `test_retention_score.py` (NEW)
- `test_smart_compression.py` (NEW)
- `test_memory_pinning.py` (NEW)
- `test_forgetting_ledger.py` (NEW)
- `test_sf_v2_integration.py` (NEW)

**Test Categories:**

1. **Unit Tests** (each component):
 - Memory role classification accuracy
 - Entity extraction completeness
 - Retention score calculation
 - Compression format preservation
 - Pin operations
 - Ledger logging

2. **Integration Tests**:
 - End-to-end flow: ingest â†’ classify â†’ extract â†’ score â†’ compress â†’ log
 - Pin + consolidation interaction
 - RL policy + retention score
 - Multi-audience with pinned memories

3. **Property Tests**:
 - Entities never lost (property)
 - Root causes always preserved (property)
 - Pinned memories immune to all operations (property)
 - Compression reversibility (when flagged)

4. **Performance Tests**:
 - Entity extraction: <10ms per memory
 - Retention scoring: <5ms per memory
 - Pin check: <1ms per query
 - Ledger logging: <2ms per event

5. **Acceptance Tests**:
 - **Test 1: No Knowledge Loss**
 ```python
 # Given: Complex debugging session with root cause
 # When: Compressed with COST_FOCUSED profile
 # Then: AI can still solve the problem from compressed memory
 ```

 - **Test 2: Entity Preservation**
 ```python
 # Given: Memory with 50 technical entities
 # When: Aggressive consolidation
 # Then: All 50 entities intact and queryable
 ```

 - **Test 3: Pin Immunity**
 ```python
 # Given: Pinned memory with NOISE salience
 # When: Run consolidation + decay
 # Then: Memory unchanged and still accessible
 ```

 - **Test 4: Smart Compression**
 ```python
 # Given: 100 error logs + 1 resolution
 # When: Consolidate group
 # Then: Output has cause/fix/result/learning format
 ```

 - **Test 5: Transparency**
 ```python
 # Given: Consolidation removes 80 memories
 # When: Check forgetting ledger
 # Then: Event logged with full details
 ```

**Test Coverage Goals:**
- Unit tests: 90%+ coverage
- Integration tests: All critical paths
- Property tests: All invariants
- Performance tests: All latency requirements
- Acceptance tests: All user scenarios

**Success Criteria:**
- All tests passing
- No regressions in existing functionality
- Performance within targets
- User scenarios validated

---

## ðŸ”„ Implementation Order

```
SF-2.1: Memory Role Classification (3-4 hours)
 â†“
SF-2.2: Entity Extraction (4-5 hours)
 â†“
SF-2.3: Retention Scoring (3-4 hours)
 â†“
SF-2.5: Memory Pinning (4-5 hours) â† Can be parallel with SF-2.4
 â†“
SF-2.4: Intelligence-Preserving Compression (6-8 hours) â† Depends on SF-2.1, SF-2.2, SF-2.3
 â†“
SF-2.6: Default Profile Change (1-2 hours)
 â†“
SF-2.7: Transparency & Auditability (3-4 hours)
 â†“
SF-2.8: Comprehensive Testing (8-10 hours)
```

**Total Estimated Time:** 32-42 hours (4-5 days)

---

## ðŸ“Š Success Metrics

### Quantitative Metrics
- **No Knowledge Loss**: AI success rate on debugging tasks â‰¥95% (before and after compression)
- **Entity Preservation**: 100% of technical entities preserved
- **Compression Ratio**: 60-80% reduction in token count (BALANCED profile)
- **Query Performance**: <50ms for pinned memory checks
- **User Trust**: â‰¥90% of users trust Vidurai's forgetting decisions

### Qualitative Metrics
- **Developer Trust**: "I trust Vidurai won't lose important details"
- **Usefulness**: "Compressed memories are still useful"
- **Transparency**: "I understand what was forgotten and why"
- **Control**: "I can pin critical knowledge"

---

## ðŸŽ“ Philosophy Alignment

This implementation embodies **à¤µà¤¿à¤¸à¥à¤®à¥ƒà¤¤à¤¿ à¤­à¥€ à¤µà¤¿à¤¦à¥à¤¯à¤¾ à¤¹à¥ˆ** (Forgetting too is knowledge):

1. **Intelligent Forgetting**: Not all forgetting is loss. Sometimes consolidation reveals patterns.
2. **Semantic Preservation**: Forget the surface, preserve the essence.
3. **Entity Anchoring**: Technical details are anchorsâ€”never let them drift.
4. **Role-Based Value**: A resolution is worth more than 100 error logs.
5. **User Agency**: Pin what matters to you, trust the system for the rest.
6. **Radical Transparency**: Every forgetting event is auditable.

---

## ðŸ“ Acceptance Criteria

Vidurai SF-V2 passes when:

 **Compression Preserves Knowledge**
 - When compressed memory is given to an AI, it can still solve the same problem

 **Smart Forgetting Feels Human-Like**
 - Vidurai retains: patterns, dependencies, pitfalls, successful strategies
 - Vidurai forgets: surface details, redundant logs, noise

 **Trust Increases, Not Decreases**
 - Developers trust Vidurai's memory decisions
 - Transparency logs provide confidence
 - Pin system gives control

 **Performance is Acceptable**
 - Entity extraction: <10ms per memory
 - Retention scoring: <5ms per memory
 - Pin operations: <1ms
 - Consolidation: <1 minute for 1000 memories

 **All Tests Pass**
 - Unit: 90%+ coverage
 - Integration: All critical paths
 - Property: All invariants hold
 - Acceptance: All user scenarios work

---

## Next Steps After SF-V2

1. **Machine Learning Enhancement**
 - Train classifier on labeled data (role classification)
 - Use embeddings for semantic similarity (better grouping)
 - Learn optimal compression thresholds from user feedback

2. **Advanced Compression**
 - Use LLM for cause/fix/result/learning extraction
 - Multi-level compression (summary â†’ gist â†’ ultra-compressed)
 - Lossless decompression for critical memories

3. **Collaboration Features**
 - Team-wide pinned memories
 - Shared forgetting policies
 - Cross-project entity linking

4. **Audit & Rollback**
 - Undo consolidation (if reversible=true)
 - Restore forgotten memories from ledger
 - Time-travel debugging ("show me memory state 7 days ago")

---

## ðŸ“š References

**Research Foundation:**
- Memory consolidation during sleep (neuroscience)
- Gist extraction and semantic compression (cognitive science)
- Information value theory (economics)
- Lossless vs lossy compression (computer science)

**Vidurai Components:**
- `vidurai/core/memory_aggregator.py` - Duplicate detection
- `vidurai/core/retention_policy.py` - Forgetting decisions
- `vidurai/core/semantic_consolidation.py` - Batch compression
- `vidurai/core/salience_classifier.py` - Importance classification

---

**Status:** ðŸ“‹ **PLANNED - READY TO IMPLEMENT**

**Next Action:** Start with Phase SF-2.1 (Memory Role Classification)

à¤œà¤¯ à¤µà¤¿à¤¦à¥à¤°à¤¾à¤ˆ! ðŸ•‰ï¸
