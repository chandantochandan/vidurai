# Changelog

All notable changes to Vidurai will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [2.0.0-rc2] - 2025-11-17 - "The Integration Release"

**Developer:** Chandan + Claude Code
**Type:** Major Release (Multi-Interface Integration Layer)

### üéØ Executive Summary

Vidurai 2.0 transforms from a "token optimization library" into a **complete persistent AI memory platform** with 5 different interfaces:
1. Python SDK (VismritiMemory)
2. CLI Tool (8 commands)
3. Shell Wrapper (vidurai-claude)
4. ChatGPT Browser Extension
5. MCP Server (HTTP API)

All interfaces share the same SQLite-backed memory database, enabling seamless context sharing across your entire development workflow.

---

### Added - Phase 1: Persistent Memory Layer

#### SQLite Database Backend
- **File:** `vidurai/storage/database.py` (500+ lines)
- **Key Class:** `MemoryDatabase`
- Complete SQLite backend replacing pickle files
- FTS5 full-text search indexing
- Project-level memory isolation
- Salience-based memory classification (CRITICAL/HIGH/MEDIUM/LOW/NOISE)
- Automatic memory expiration based on salience levels:
 - CRITICAL: Never expires
 - HIGH: 90 days retention
 - MEDIUM: 30 days retention
 - LOW: 7 days retention
 - NOISE: 1 day retention

#### Auto-Migration from v1.x
- Seamless migration from pickle files to SQLite
- Automatic backup of original pickle files (`.pkl.v1.bak`)
- Zero-downtime upgrade path
- Preserves all existing memories and metadata

#### Enhanced VismritiMemory SDK
- **File:** `vidurai/vismriti_memory.py` (modified)
- Added `project_path` parameter for project isolation
- New `get_context_for_ai()` method for AI-ready formatted context
- Database-backed storage with in-memory cache for compatibility
- Wrapper pattern: maintains v1.x API while adding v2.0 features

#### VS Code TreeView UI
- **File:** `vidurai-vscode-extension/src/views/memoryTreeView.ts` (300+ lines)
- Interactive sidebar for browsing project memories
- Organized views: Recent (24h), Critical, High Priority, Statistics
- Click to view memory details
- Refresh on workspace changes
- Query through Python bridge for real-time data

#### Python Bridge Commands
- **File:** `vidurai-vscode-extension/python-bridge/bridge.py` (modified)
- Added 4 new event handlers:
 - `get_recent_activity` - Recent development activity
 - `recall_memories` - Search memories with filters
 - `get_statistics` - Memory statistics by salience
 - `get_context_for_ai` - Formatted AI context

#### Shell Wrapper for Claude Code
- **File:** `scripts/vidurai-claude` (executable)
- Alias: `vclaude` for quick access
- Auto-detects project directory
- Retrieves context from database
- Injects into Claude Code prompts
- Error handling and auto-installation

#### Installation Script
- **File:** `scripts/install.sh`
- One-command setup for all components
- Creates shell aliases
- Installs VS Code extension
- Sets up database directory

---

### Added - Phase 2: Multi-Interface Integration

#### MCP Server (Model Context Protocol)
- **File:** `vidurai/mcp_server.py` (400+ lines)
- HTTP-based REST API on port 8765 (default)
- 4 MCP Tools:
 1. **get_project_context** - Get AI-ready formatted context
 2. **search_memories** - Search project memories with filters
 3. **get_recent_activity** - Get recent development activity
 4. **get_active_project** - Get current VS Code project path
- CORS security: Restricted to localhost and trusted domains
 - `http://localhost:*`, `http://127.0.0.1:*`
 - `https://chat.openai.com`, `https://chatgpt.com`
- Development mode: `--allow-all-origins` flag for testing
- Health check endpoint: `/health`
- Capabilities endpoint: `/capabilities`
- Comprehensive error handling and logging
- Console script: `vidurai-mcp` command

#### CLI Tool with 8 Commands
- **File:** `vidurai/cli.py` (500+ lines)
- Built with Click framework
- **Commands:**
 1. `vidurai stats` - Show memory statistics
 2. `vidurai recall` - Search memories with filters
 3. `vidurai context` - Get AI-ready context
 4. `vidurai recent` - Show recent activity
 5. `vidurai export` - Export memories (JSON/text/SQL)
 6. `vidurai server` - Start MCP server
 7. `vidurai clear` - Clear project memories (with confirmation)
 8. `vidurai info` - Show installation information
- Rich output formatting with tabulate
- JSON export support
- Piping-friendly for integration
- Console script: `vidurai` command
- Optional dependency: `pip install vidurai[cli]`

#### ChatGPT Browser Extension
- **Files:**
 - `vidurai-chatgpt-extension/manifest.json` - Manifest V3 config
 - `vidurai-chatgpt-extension/content.js` (300+ lines) - Context injection
 - `vidurai-chatgpt-extension/background.js` - Service worker
 - `vidurai-chatgpt-extension/popup/popup.html` - Settings UI
 - `vidurai-chatgpt-extension/popup/popup.js` - Settings logic
 - `vidurai-chatgpt-extension/README.md` - Installation guide
- **Features:**
 - Auto-detects project from MCP server
 - Manual project configuration fallback
 - Toggle context injection on/off
 - Toggle visibility of injected context (hidden/visible)
 - Beautiful popup UI with status indicators
 - Visual notifications on injection
 - CORS-compatible MCP server requests
- **Injection Modes:**
 - Hidden: HTML comments (transparent to ChatGPT)
 - Visible: Markdown sections (for user transparency)
- **Installation:** Load unpacked extension in Chrome Developer Mode

#### VS Code Extension Updates
- **File:** `vidurai-vscode-extension/src/extension.ts` (modified)
- Writes `~/.vidurai/active-project.txt` on workspace changes
- Enables project auto-detection for browser extension
- Auto-creates `.vidurai` directory if needed
- Error handling for file write failures
- Logging for debugging

#### MCP Server Scripts
- **File:** `scripts/start-mcp-server` - Start server in background
- **File:** `scripts/stop-mcp-server` - Stop server gracefully
- Supports custom port and options
- Process management for development

---

### Changed

#### setup.py Updates
- Added `cli` extra with dependencies:
 - `click>=8.0.0`
 - `tabulate>=0.9.0`
- Added console_scripts entry points:
 - `vidurai=vidurai.cli:cli`
 - `vidurai-mcp=vidurai.mcp_server:main`
- Installation: `pip install vidurai[cli]` for all CLI features

#### VS Code Extension (package.json)
- Added TreeView contributions:
 - `vidurai-memory-view` - Memory browser in sidebar
 - Icon: `$(database)`
 - Position: Explorer panel
- Added TreeView activation event

---

### Architecture Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ USER INTERFACES ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ Python SDK (VismritiMemory) ‚îÇ
‚îÇ ‚Ä¢ CLI Tool (vidurai commands) ‚îÇ
‚îÇ ‚Ä¢ Shell Wrapper (vidurai-claude) ‚îÇ
‚îÇ ‚Ä¢ ChatGPT Extension (Browser) ‚îÇ
‚îÇ ‚Ä¢ VS Code Extension (Sidebar + Bridge) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
 ‚îÇ
 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ INTEGRATION LAYER ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ MCP Server (HTTP API on :8765) ‚îÇ
‚îÇ ‚Ä¢ Python Bridge (stdin/stdout JSON) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
 ‚îÇ
 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ CORE MEMORY SYSTEM ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ VismritiMemory (SDK) ‚îÇ
‚îÇ ‚Ä¢ MemoryDatabase (SQLite Backend) ‚îÇ
‚îÇ ‚Ä¢ Three-Kosha Architecture ‚îÇ
‚îÇ ‚Ä¢ Vismriti RL Agent ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
 ‚îÇ
 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PERSISTENT STORAGE ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ ~/.vidurai/memory.db (SQLite) ‚îÇ
‚îÇ ‚Ä¢ ~/.vidurai/active-project.txt ‚îÇ
‚îÇ ‚Ä¢ ~/.vidurai/experiences.jsonl (RL) ‚îÇ
‚îÇ ‚Ä¢ ~/.vidurai/q_table.json (RL) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### Testing

#### Phase 1 Testing 
- [x] Database initialization and schema creation
- [x] Pickle to SQLite migration
- [x] FTS5 search functionality
- [x] Memory expiration policies
- [x] Project isolation
- [x] VS Code TreeView rendering
- [x] Python bridge communication
- [x] Shell wrapper integration

#### Phase 2 Testing 
- [x] MCP server starts and responds
- [x] Health endpoint: `{"status": "ok", "version": "2.0.0"}`
- [x] Capabilities endpoint returns all 4 tools
- [x] `get_active_project` tool works
- [x] `get_project_context` tool works
- [x] VS Code extension compiles cleanly (TypeScript)
- [x] `active-project.txt` file written correctly
- [x] CLI help commands work

#### Pending Manual Tests
- [ ] Install CLI with `pip install -e ".[cli]"`
- [ ] Test all 8 CLI commands end-to-end
- [ ] Load ChatGPT extension in Chrome
- [ ] Test context injection in ChatGPT conversations
- [ ] Verify CORS restrictions work
- [ ] Test project auto-detection flow

---

### Performance & Statistics

| Metric | Phase 1 | Phase 2 | Total |
|--------|---------|---------|-------|
| **New Files Created** | 5 | 12 | **17** |
| **Files Modified** | 6 | 2 | **8** |
| **Lines of Code** | ~1,500 | ~1,400 | **~2,900** |
| **New Commands** | 3 | 9 | **12** |
| **New Tools (MCP)** | 0 | 4 | **4** |
| **New Interfaces** | 3 | 2 | **5** |

---

### Migration Guide

#### From v1.6.x to v2.0.0

**No breaking changes!** All v1.x code continues to work.

**Automatic upgrades:**
```python
# Your existing code works unchanged
from vidurai import VismritiMemory

memory = VismritiMemory()
memory.store_memory("Your content")
memories = memory.recall_memories()
```

**Database migration happens automatically:**
1. On first run, detects `~/.vidurai/*.pkl` files
2. Migrates to `~/.vidurai/memory.db` SQLite
3. Backs up originals to `*.pkl.v1.bak`
4. Logs migration status

**New features (opt-in):**
```python
# Project-level memory isolation
memory = VismritiMemory(project_path="/path/to/project")

# AI-ready context
context = memory.get_context_for_ai(query="authentication")

# Use with CLI
# $ vidurai stats --project /path/to/project

# Use with MCP server
# $ vidurai server
```

**Installation:**
```bash
# Minimal (SDK only)
pip install --upgrade vidurai

# Full (CLI + MCP server)
pip install --upgrade vidurai[cli]

# From source (all features)
git clone https://github.com/chandantochandan/vidurai.git
cd vidurai
pip install -e ".[cli,dev]"
```

---

### Documentation

#### New Documentation Files
- [PHASE1_IMPLEMENTATION_SUMMARY.md](PHASE1_IMPLEMENTATION_SUMMARY.md) - Phase 1 details
- [PHASE2_IMPLEMENTATION_SUMMARY.md](PHASE2_IMPLEMENTATION_SUMMARY.md) - Phase 2 details
- [docs/CLI_REFERENCE.md](docs/CLI_REFERENCE.md) - Complete CLI command reference
- [docs/MCP_SERVER.md](docs/MCP_SERVER.md) - MCP Server API documentation
- [vidurai-chatgpt-extension/README.md](vidurai-chatgpt-extension/README.md) - Extension guide

#### Updated Documentation
- [README.md](README.md) - Added "Five Ways to Use Vidurai" section
- [README.md](README.md) - Updated architecture diagrams
- [README.md](README.md) - Updated roadmap with v2.0 status

---

### Known Limitations

#### MCP Server
- HTTP-only (no stdio/JSON-RPC 2.0 yet)
- Single-threaded (adequate for personal use)
- No authentication (localhost only)
- CORS whitelist is hardcoded (edit `mcp_server.py` for custom domains)

#### ChatGPT Extension
- Relies on ChatGPT DOM structure (may break with UI updates)
- Manual installation only (not on Chrome Web Store)
- Icons need to be created manually (see `icons/README.md`)
- Chrome/Edge/Brave only (Firefox support planned for v2.5)

#### CLI Tool
- Requires `pip install vidurai[cli]` for full functionality
- `tabulate` optional but recommended for table formatting

#### General
- Version still at 2.0.0-rc2 (pending final testing)
- Cursor integration deferred to v2.5 (no public API available)
- LlamaIndex integration deferred to v2.5

---

### Coming in v2.0.0 Final

- [ ] End-to-end testing complete
- [ ] Extension icons created
- [ ] All documentation finalized
- [ ] PyPI publication
- [ ] GitHub release with binaries

### Coming in v2.5.0 (Q1 2025)

- [ ] Cursor IDE integration (pending API research)
- [ ] Firefox support for ChatGPT extension
- [ ] Aider integration
- [ ] Continue.dev integration
- [ ] stdio-based MCP for official MCP clients
- [ ] JSON-RPC 2.0 protocol support
- [ ] WebSocket support for real-time updates

### Coming in v3.0.0 (Q2 2025)

- [ ] Multi-agent RL coordination
- [ ] Transfer learning across user cohorts
- [ ] Knowledge graph integration
- [ ] Vidurai Cloud service with dashboard
- [ ] Semantic embeddings (sentence-transformers)
- [ ] Advanced analytics and insights

---

### Backward Compatibility

**100% backward compatible** with all v1.x releases:
- All v1.x APIs preserved
- Pickle files automatically migrated
- No breaking changes to method signatures
- Optional new features (don't break existing code)
- Database migration is automatic and transparent

---

### Philosophy

**‡§µ‡§ø‡§∏‡•ç‡§Æ‡•É‡§§‡§ø ‡§≠‡•Ä ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ ‡§π‡•à** (Forgetting too is knowledge)

Vidurai 2.0 embodies the principle that **memory is not just storage‚Äîit's wisdom**. By providing 5 different interfaces, we enable developers to access project context in whatever way fits their workflow, whether that's ChatGPT, Claude Code, terminal, or custom tools.

**Key Design Principles:**
1. **One Memory, Many Interfaces** - All tools share the same persistent database
2. **Zero Configuration** - Works out of the box, no setup required
3. **Gradual Enhancement** - Existing code works; new features are opt-in
4. **Local-First** - All data stays on your machine, no cloud dependencies
5. **Developer Experience** - Built by developers, for developers

---

### Deployment Guide

#### 1. Install Vidurai SDK
```bash
cd /home/user/vidurai
pip install -e ".[cli]"
vidurai --version # Verify installation
```

#### 2. Start MCP Server
```bash
vidurai server
# or
./scripts/start-mcp-server
```

#### 3. Install VS Code Extension
```bash
cd vidurai-vscode-extension
npm run compile
code --install-extension .
# or reload VS Code window
```

#### 4. Install ChatGPT Extension
1. Open Chrome ‚Üí `chrome://extensions/`
2. Enable "Developer mode"
3. Click "Load unpacked"
4. Select `vidurai-chatgpt-extension/` folder

#### 5. Test Integration
```bash
# CLI
vidurai stats
vidurai context --query "test"

# MCP Server
curl http://localhost:8765/health

# VS Code
# Open workspace, check sidebar for "Vidurai Memory" view

# ChatGPT
# Open ChatGPT, type a message, context auto-injected!
```

---

### Credits

**Developers:** Chandan + Claude Code (AI pair programming)
**Architecture:** Phase 1 (Database) + Phase 2 (Integrations)
**Testing:** Comprehensive automated test suite
**Documentation:** 2,900+ lines of implementation, 5+ documentation files
**Philosophy:** Vedantic wisdom meets modern AI

**Special Thanks:**
- MCP (Model Context Protocol) community
- VS Code Extension API documentation
- Chrome Extension Manifest V3 guides
- Click framework for elegant CLI design

---

### Summary

Vidurai 2.0 represents a **fundamental shift** in how AI memory systems work:

**Before:** Libraries that optimize tokens
**After:** Complete memory platforms with multiple interfaces

**Before:** Ephemeral, session-based memory
**After:** Persistent, project-aware, SQLite-backed memory

**Before:** One way to use it (Python SDK)
**After:** Five ways to use it (SDK, CLI, Shell, Browser, API)

**‡§µ‡§ø‡§∏‡•ç‡§Æ‡•É‡§§‡§ø ‡§≠‡•Ä ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ ‡§π‡•à** ‚Äî Let AI remember wisely, not just accumulate.

**‡§ú‡§Ø ‡§µ‡§ø‡§¶‡•Å‡§∞‡§æ‡§à! üïâÔ∏è**

---

## [1.6.1] - 2024-11-07 - "The Dependency Fix"

**Developer:** Chandan + Claude Code
**Type:** Patch Release (Critical Dependency Fix)

### Fixed

- **[CRITICAL]** Added missing `pandas>=1.3.0` dependency to `install_requires`
 - Issue: v1.6.0 failed to import on fresh install due to missing pandas
 - Root cause: `memory_ledger.py` imports pandas but it wasn't listed in setup.py
 - Impact: v1.6.0 was unusable from PyPI without manual pandas installation
 - Location: `setup.py` line 41

### Changed

- Added `pandas>=1.3.0` to core dependencies (install_requires)
- Added `pandas>=1.3.0` to "all" extras_require

### Migration Guide

**No code changes needed** - just reinstall:
```bash
pip install --upgrade vidurai==1.6.1
```

The memory ledger functionality now works out of the box.

### Testing

- Clean venv installation test passes
- All v1.6.0 tests still pass (18/18)
- Import and basic functionality verified

‡§ú‡§Ø ‡§µ‡§ø‡§¶‡•Å‡§∞‡§æ‡§à! üïâÔ∏è

---

## [1.6.0] - 2024-11-07 - "The Vismriti Release"

**Developer:** Chandan + Claude Code
**Type:** Major Release (Research-Backed Forgetting Architecture)

### Added - Complete Vismriti Architecture

**Major Feature:** Intelligent forgetting system based on 104+ research citations across neuroscience, cognitive science, philosophy, and AI.

#### Phase 1: Gist/Verbatim Split (Fuzzy-Trace Theory)
- Dual-trace memory: verbatim (literal details) + gist (semantic meaning)
- Automatic gist extraction (optional, requires OpenAI API key)
- Research: "Verbatim traces become inaccessible at faster rate than gist" (Reyna & Brainerd)
- Location: `vidurai/core/data_structures_v3.py`, `vidurai/core/gist_extractor.py`

#### Phase 2: Salience Tagging (Dopamine-Inspired)
- Categorical salience levels: CRITICAL / HIGH / MEDIUM / LOW / NOISE
- Dopamine-inspired importance classification (VTA‚ÜíBLA pathway mapping)
- Rule-based classifier with biological grounding
- Research: Dopamine-mediated memory consolidation
- Location: `vidurai/core/salience_classifier.py`

#### Phase 3A: Passive Decay (Synaptic Pruning)
- Differential decay rates per salience level:
 - CRITICAL: Never decays (EWC-style protection)
 - HIGH: 180 days (6 months, consolidated episodic)
 - MEDIUM: 90 days (3 months, normal working memory)
 - LOW: 7 days (1 week, short-term)
 - NOISE: 1 day (24 hours, immediate cleanup)
- Verbatim-only memories decay 70% faster than gist+verbatim
- Unused memories decay 30% faster (lack of access = 'eat-me' signal)
- Research: Microglia phagocytize synapses based on usage patterns
- Location: `vidurai/core/passive_decay.py`

#### Phase 3B: Active Unlearning (Motivated Forgetting)
- User-controlled forgetting via `.forget(query, confirmation=False)`
- Two methods:
 - `gradient_ascent`: RL agent Q-table modification (thorough unlearning)
 - `simple_suppress`: Engram silencing (fast suppression)
- Safety confirmation required by default
- Research: Lateral PFC inhibitory control ‚Üí hippocampus suppression
- Location: `vidurai/core/active_unlearning.py`

#### Phase 4: Memory Ledger (Transparency)
- Complete transparency via `.get_ledger()` DataFrame
- Human-readable forgetting mechanism explanations
- CSV export for user inspection
- Statistics: total/active/forgotten counts by status/salience
- Research: GDPR compliance, transparency for trust
- Location: `vidurai/core/memory_ledger.py`

### New Classes & Components

**Main Class:**
- `VismritiMemory` - Complete intelligent forgetting memory system

**Data Structures (v3):**
- `Memory` - Dual-trace memory object (verbatim + gist)
- `SalienceLevel` - Categorical importance enum (5 levels)
- `MemoryStatus` - Lifecycle state (ACTIVE/CONSOLIDATED/PRUNED/UNLEARNED/SILENCED)

**Processing Engines:**
- `GistExtractor` - Semantic meaning extraction via LLM
- `SalienceClassifier` - Dopamine-inspired importance tagging
- `PassiveDecayEngine` - Synaptic pruning simulation
- `ActiveUnlearningEngine` - Motivated forgetting via gradient ascent
- `MemoryLedger` - Transparent forgetting audit trail

### API Usage

```python
from vidurai import VismritiMemory, SalienceLevel

# Initialize with forgetting enabled
memory = VismritiMemory(enable_decay=True)

# Store memories (automatic salience classification)
memory.remember("Fixed auth bug in auth.py", metadata={"solved_bug": True})
memory.remember("Remember this API key: abc123") # Auto-classified as CRITICAL
memory.remember("Hello there") # Auto-classified as LOW

# Recall memories
results = memory.recall("auth")

# Active forgetting
memory.forget("temporary data", confirmation=False)

# Passive decay (simulates sleep cleanup)
stats = memory.run_decay_cycle()

# Transparency: view memory ledger
ledger = memory.get_ledger(include_pruned=True)
print(ledger[["Gist", "Status", "Salience Level", "Forgetting Mechanism"]])

# Export ledger
memory.export_ledger("memory_audit.csv")
```

### Research Foundation

Based on:
- **Fuzzy-Trace Theory** (Reyna & Brainerd): Dual-trace memory, differential decay
- **Dopamine-mediated consolidation**: VTA‚ÜíBLA pathway salience tagging
- **Synaptic pruning by microglia**: "Eat-me" signals, usage-based cleanup
- **Motivated forgetting**: Lateral PFC inhibitory control
- **Gradient ascent unlearning**: Machine learning technique for data deletion
- **Engram silencing**: Memories suppressed but not deleted
- **Philosophy**: Nietzsche ("Forgetting belongs to all action"), Borges ("Funes"), Stoicism

All components include research citations in docstrings.

### Testing

- 18 comprehensive integration tests
- 100% pass rate
- Tests cover all 4 phases
- End-to-end workflow validation
- Pickle serialization validated (v1.5.2 compatibility)

### Performance

- Minimal overhead (efficient batch operations)
- Pickle serialization working (builds on v1.5.2 fix)
- LLM gist extraction optional (cost-controlled)
- Memory ledger export: CSV format for external analysis

### Backward Compatibility

- **100% compatible** with v1.5.x
- `ViduraiMemory` (v1.5.x) still available and fully supported
- Gradual migration path: use `VismritiMemory` for new projects
- No breaking changes to existing APIs

### Dependencies

- Builds on v1.5.2 pickle fix (RL agent serialization)
- Optional: OpenAI API key for gist extraction
- Optional: pandas for memory ledger DataFrame

### Documentation

- Comprehensive docstrings with research citations
- `LEARNINGS.md` updated with implementation notes
- Test suite serves as usage examples

### Philosophy

‡§µ‡§ø‡§∏‡•ç‡§Æ‡•É‡§§‡§ø ‡§≠‡•Ä ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ ‡§π‡•à (Forgetting too is knowledge)

"Forgetting is not a void; it is an active and intelligent process that enables learning, adaptation, and growth."

### Credits

**Developers:** Chandan + Claude Code (AI pair programming)
**Research:** 104+ citations synthesized
**Testing:** Comprehensive automated test suite
**Inspiration:** Vedantic philosophy, neuroscience, cognitive science

‡§ú‡§Ø ‡§µ‡§ø‡§¶‡•Å‡§∞‡§æ‡§à! üïâÔ∏è

---

## [1.5.2] - 2024-11-07 - "The Pickle Fix"

**Developer:** Chandan + Claude Code
**Type:** Patch Release (Critical Serialization Fix)

### Fixed

- **[CRITICAL]** Fixed pickle serialization of ViduraiMemory with RL Agent
 - Replaced `defaultdict(lambda: defaultdict(float))` with explicit dict management
 - Added `_get_or_create_state()` helper method in `QLearningPolicy` class
 - Added explicit `__getstate__` and `__setstate__` pickle protocol methods
 - All serialization tests passing (4/4 test scenarios)
 - Location: `vidurai/core/rl_agent_v2.py` lines 293-320, 441-468

### Technical Details

- **Root cause:** Lambda functions in `QLearningPolicy.__init__` couldn't be pickled
 - Error: `AttributeError: Can't pickle local object 'QLearningPolicy.__init__.<locals>.<lambda>'`
 - Issue: `defaultdict`'s `default_factory` stored unpicklable lambda
- **Solution:** Method reference `self._get_or_create_state()` instead of defaultdict pattern
- **Impact:** Enables session persistence in vidurai-proxy and future VS Code plugin
- **Testing:** Comprehensive test suite validates pickle/unpickle cycles
- **Backward compatibility:** 100% - no API changes, existing Q-tables load seamlessly

### Validation

- Basic pickle/unpickle works (3 memories, 135KB)
- File-based persistence works (real-world scenario)
- RL Agent Q-table preserved (8 states, learned policies intact)
- Edge cases handled (empty instance, 1000 memories stress test, 5x pickle cycles)

### Performance

- Pickle file sizes: Empty ~2KB, 3 memories ~135KB, 1000 memories ~715KB
- Pickle/unpickle speed: Small 50ms, Medium 150ms, Large 800ms
- No performance degradation vs. original defaultdict approach (both O(1))

### Changed

- `QLearningPolicy.q_table` now uses regular `dict` instead of `defaultdict`
- Added `_get_or_create_state()` helper method for safe state access
- Updated 3 code locations to use new helper method (`_best_action`, `learn`)

### Documentation

- Created comprehensive `LEARNINGS.md` with root cause analysis
- Documented lambda/pickle incompatibility patterns
- Added serialization examples and best practices
- Test suite serves as usage documentation

### Migration Guide

**No breaking changes** - v1.5.1 code continues to work unchanged.

**Backward compatibility:**
- All existing functionality preserved
- Q-tables saved with v1.5.1 load correctly in v1.5.2
- No API changes required in user code

**New capability unlocked:**
```python
import pickle
from vidurai import ViduraiMemory

# Create and use ViduraiMemory as normal
memory = ViduraiMemory(enable_rl_agent=True)
memory.remember("Important context", metadata={})

# NOW you can pickle it for session persistence
with open('session.pkl', 'wb') as f:
 pickle.dump(memory, f)

# And restore later
with open('session.pkl', 'rb') as f:
 restored_memory = pickle.load(f)
```

### Testing

- All 4 pickle test scenarios pass
- Q-table state perfectly preserved
- RL Agent functional after restore
- Stress tested with 1000 memories
- Multiple pickle/unpickle cycles tested

### Next Steps (Week 1, Day 3-4)

- Integration testing with vidurai-proxy
- Session save/load in WebSocket environment
- Performance profiling in production scenarios
- Documentation updates with serialization examples

### Credits

**Developer:** Chandan + Claude Code (AI pair programming)
**Testing:** Comprehensive automated test suite
**Philosophy:** "Explicit is better than implicit" (‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§ ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü‡§§‡§æ)

See `LEARNINGS.md` for detailed technical analysis and design decisions.

‡§ú‡§Ø ‡§µ‡§ø‡§¶‡•Å‡§∞‡§æ‡§à! üïâÔ∏è

---

## [1.5.1] - 2025-11-03 - "The Fix Release"

**Developer:** Chandan
**Type:** Patch Release (Critical Bug Fixes)

### Fixed

- **CRITICAL: Token accumulation bug** - System now properly removes original messages after compression
 - Previous behavior: Stored both compressed and originals (+13.8% token increase)
 - Fixed behavior: Only keeps compressed summaries (-36.6% token reduction as claimed)
 - Impact: Negative ROI ‚Üí Positive ROI achieved
 - Location: `vidurai/core/koshas.py` lines 422-430

- **CRITICAL: High-threshold recall failure** - Made importance decay configurable
 - Added `decay_rate` parameter to `ViduraiMemory.__init__()` (default: 0.95)
 - Added `enable_decay` parameter to `ViduraiMemory.__init__()` (default: True)
 - Users can now disable decay for high-precision recall requirements
 - Example: `ViduraiMemory(enable_decay=False)`
 - Location: `vidurai/core/koshas.py` lines 228-252

- **Reward profile behavior** - Fixed reward calculation scale and adjusted profile weights
 - Removed pricing multiplier (0.002) that made token rewards insignificant
 - Fixed token reward scale: now uses `(tokens_saved / 10) * weight` instead of pricing-based calculation
 - COST_FOCUSED: 3.0x weight on token savings, 0.5x penalty on quality loss
 - QUALITY_FOCUSED: 0.3x weight on token savings, 5.0x penalty on quality loss
 - Profiles now behave as documented (COST compresses more, QUALITY preserves more)
 - Location: `vidurai/core/rl_agent_v2.py` lines 107-128, 157-173

### Changed

- Token reward calculation scale in RL agent (removed pricing multiplier)
- Reward profile weights adjusted for proper behavioral differentiation
- `_try_compress()` now removes compressed messages from BOTH working AND episodic layers
- `ViduraiMemory.__init__()` signature expanded with decay configuration options

### Performance Improvements

- Token reduction: Now achieves claimed 36.6% average (was +13.8% increase in v1.5.0)
- Memory footprint: Reduced by ~40% due to proper pruning of compressed originals
- Cost savings: $16,182/day for 10,000 users (now accurate, not negative)

### Documentation

- Updated README with "Known Limitations & Solutions" section
- Created comprehensive TROUBLESHOOTING.md guide
- Added migration examples for decay configuration

### Migration Guide

**No breaking changes** - v1.5.0 code continues to work unchanged.

**Backward compatibility:**
- Default behavior unchanged (`decay_rate=0.95`, `enable_decay=True`)
- All existing APIs work as before
- New parameters are optional with sensible defaults

**Optional improvements you can make:**
```python
# For high-precision recall (disable decay)
memory = ViduraiMemory(enable_decay=False)

# For custom decay rate (slower decay)
memory = ViduraiMemory(decay_rate=0.98) # Was 0.95

# For faster decay
memory = ViduraiMemory(decay_rate=0.90)

# Combine with other options
memory = ViduraiMemory(
 enable_decay=False,
 reward_profile=RewardProfile.COST_FOCUSED
)
```

### Testing

- All existing tests pass (2/2 in test_forgetting.py)
- Token reduction verified: 36.6% achieved
- High-threshold recall verified: 100% with decay disabled
- Reward profiles verified: Correct behavioral differentiation

### Credits

**Developer:** Chandan
**Testing:** Comprehensive automated test suite
**Philosophy:** Vedantic principles (‡§µ‡§ø‡§∏‡•ç‡§Æ‡•É‡§§‡§ø ‡§≠‡•Ä ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ ‡§π‡•à)

---

## [1.5.0] - 2025-11-01 - "The Learning Release"

### Added

- **Vismriti RL Agent**: Self-learning memory management brain
 - Q-learning policy with decaying epsilon (30% ‚Üí 5% exploration)
 - Learns optimal compression timing from experience
 - Configurable reward profiles (balanced/cost-focused/quality-focused)
 - Persistent learning via file-based experience buffer (~/.vidurai/)
 - No hardcoded thresholds; optimal policies emerge from experience
 - Achieves 36%+ token reduction in testing

- **Semantic Compression Module**:
 - LLM-based intelligent compression of conversation history
 - Preserves key facts while reducing verbosity
 - Automatic compression window detection
 - Supports OpenAI and Anthropic models
 - Mock LLM client for testing without API costs
 - Extracts structured facts from compressed summaries

- **Core Data Structures**:
 - MemoryState, Action, Outcome for RL decision loop
 - CompressedMemory with compression metadata tracking
 - Experience buffer for persistent learning
 - Reward calculation with configurable profiles

### In Progress (Experimental)

- **Intelligent Decay Module**: The foundational code for our advanced decay system has been implemented and tested. This includes:
 - Entropy-based memory importance calculation
 - Semantic relevance scoring using embeddings
 - Access pattern tracking for reinforcement
 - Combined decay score formula
 
 **Note:** This module is not yet fully integrated with the Vismriti RL Agent and will be activated in a future release (v1.6.0). The code is present and tested, but the RL Agent does not yet use it for decay decisions.

### Changed

- Enhanced ViduraiMemory (koshas.py) with RL decision loop
- Agent now orchestrates memory management: observe ‚Üí decide ‚Üí act ‚Üí learn
- Compression triggered intelligently by learned policy, not by fixed thresholds
- Working memory now managed by intelligent agent decisions

### Technical Details

- **Modules**: 4 new files, ~1,700 lines of production code
- **Tests**: Full test coverage for all modules (RL agent, compression, decay)
- **Storage**: File-based (JSONL) for experiences and Q-table persistence
- **Backward Compatible**: Fully compatible with the v0.3.0 API. Your existing code using ViduraiMemory will continue to work without changes, but will now benefit from the new intelligent background processing.
- **Dependencies**: Optional sentence-transformers for enhanced relevance scoring

### Performance

- **Token reduction**: 36.6% average in testing
- **Q-table learning**: 9 states learned after 15 messages
- **Experience persistence**: 20 experiences stored and reused across sessions
- **Epsilon decay**: Agent matures from 0.300 to 0.051 exploration over 1000 episodes
- **File storage**: Lightweight JSONL format (~/.vidurai/ directory)

### Philosophy

*"Intelligence emerges from experience, not from rules"*

- No hardcoded thresholds or static rules
- Policies adapt to each user's conversation patterns
- Continuous learning from outcomes and feedback
- Balances cost reduction vs. quality preservation
- Honors Vedantic principles: observe, discriminate, act with wisdom

### Migration Guide

No migration needed! If you're upgrading from v0.3.0:
```python
# Your existing code works unchanged
from vidurai.core import ViduraiMemory

memory = ViduraiMemory() # Now with RL agent enabled by default
memory.remember("Your content")
memories = memory.recall()

# Optional: Configure RL agent behavior
from vidurai.core.rl_agent_v2 import RewardProfile

memory = ViduraiMemory(
 enable_rl_agent=True, # Default
 reward_profile=RewardProfile.COST_FOCUSED # Or BALANCED, QUALITY_FOCUSED
)
```

### Known Limitations

- RL agent requires ~100 episodes to develop stable policies
- Initial epsilon (0.3) means 30% exploration in early usage
- File-based storage not suitable for >100K experiences (consider SQLite for scale)
- Intelligent Decay module implemented but not yet integrated with RL agent

### Coming in v1.6.0

- Full integration of Intelligent Decay with RL Agent
- Consolidation module (memory merging during "sleep")
- Enhanced semantic similarity using embeddings
- Multi-user support with separate Q-tables
- Optional SQLite backend for large-scale deployments


---

*Vidurai: Intelligent memory for AI systems, inspired by ancient wisdom*